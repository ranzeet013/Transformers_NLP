{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d13126",
   "metadata": {},
   "source": [
    "### Neural Machine Translation (NMT) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532fe39",
   "metadata": {},
   "source": [
    "Neural Machine Translation (NMT) is a deep learning approach for automatically translating text from one language to another. It utilizes neural networks, particularly recurrent or transformer architectures, to learn complex mappings between source and target languages. NMT considers the entire input sentence at once, capturing contextual dependencies and producing more fluent translations compared to traditional methods. Training involves large parallel corpora, enabling the model to generalize across diverse language pairs. NMT has become the dominant paradigm in machine translation, offering improved translation quality and natural language understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2fc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline \n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Initialize a RegexpTokenizer for word tokenization\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Dictionary to store English to Spanish translations\n",
    "eng2spa = {}\n",
    "\n",
    "# Read the English to Spanish translation data from a file\n",
    "with open(r'C:/Users/DELL/Desktop/python project/nlp/New folder (6)/spa-eng/spa.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        eng, spa = line.split(\"\\t\")\n",
    "        eng2spa[eng] = spa\n",
    "\n",
    "# Example usage of sentence_bleu\n",
    "sentence_bleu([['hi']], ['hi'])\n",
    "\n",
    "# Smoothing the BLEU score using NLTK's SmoothingFunction\n",
    "smoother = SmoothingFunction()\n",
    "sentence_bleu([['hi']], ['hi'], smoothing_function=smoother.method4)\n",
    "\n",
    "# Tokenize the Spanish translations\n",
    "eng2spa_tokens = {}\n",
    "for eng, spa_list in eng2spa.items():\n",
    "    spa_list_tokens = []\n",
    "    for text in spa_list:\n",
    "        tokens = tokenizer.tokenize(text.lower())\n",
    "        spa_list_tokens.append(tokens)\n",
    "    eng2spa_tokens[eng] = spa_list_tokens\n",
    "    \n",
    "# Initialize a translation pipeline using the Helsinki-NLP model for English to Swedish translation\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-se\")\n",
    "\n",
    "translator('I am ranzeet.') # translates into spanish text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e498c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
