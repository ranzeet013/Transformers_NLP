{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a66aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Apple is a technology company.\",\n",
    "    \"John and Mary visited New York City.\",\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"The Eiffel Tower is located in Paris.\",\n",
    "    \"Elon Musk founded SpaceX.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3088e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee6737",
   "metadata": {},
   "source": [
    "### NER, or Named Entity Recognition :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047681c3",
   "metadata": {},
   "source": [
    "NER, or Named Entity Recognition, is a natural language processing (NLP) technique that involves identifying and classifying entities, such as names of people, organizations, locations, dates, and other specific terms, within a text. The goal of NER is to extract meaningful information and provide a structured representation of the text by labeling entities with predefined categories. This technology is crucial for various applications, including information retrieval, question answering, and sentiment analysis, as it enables machines to understand and process text at a more granular level, improving overall comprehension and usability of language-based systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6f9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline('ner', aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed91b4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'entity_group': 'ORG',\n",
       "   'score': 0.9982632,\n",
       "   'word': 'Apple',\n",
       "   'start': 0,\n",
       "   'end': 5}],\n",
       " [{'entity_group': 'PER',\n",
       "   'score': 0.9957172,\n",
       "   'word': 'John',\n",
       "   'start': 0,\n",
       "   'end': 4},\n",
       "  {'entity_group': 'PER',\n",
       "   'score': 0.9963775,\n",
       "   'word': 'Mary',\n",
       "   'start': 9,\n",
       "   'end': 13},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.9994919,\n",
       "   'word': 'New York City',\n",
       "   'start': 22,\n",
       "   'end': 35}],\n",
       " [{'entity_group': 'MISC',\n",
       "   'score': 0.8611981,\n",
       "   'word': 'Python',\n",
       "   'start': 0,\n",
       "   'end': 6}],\n",
       " [{'entity_group': 'MISC',\n",
       "   'score': 0.73485905,\n",
       "   'word': 'Eiffel',\n",
       "   'start': 4,\n",
       "   'end': 10},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.46634328,\n",
       "   'word': 'Tower',\n",
       "   'start': 11,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.9994511,\n",
       "   'word': 'Paris',\n",
       "   'start': 31,\n",
       "   'end': 36}],\n",
       " [{'entity_group': 'PER',\n",
       "   'score': 0.9980916,\n",
       "   'word': 'Elon Musk',\n",
       "   'start': 0,\n",
       "   'end': 9},\n",
       "  {'entity_group': 'ORG',\n",
       "   'score': 0.99886775,\n",
       "   'word': 'SpaceX',\n",
       "   'start': 18,\n",
       "   'end': 24}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d245e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
